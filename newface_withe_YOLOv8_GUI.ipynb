{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "import pickle\n",
    "\n",
    "\n",
    "def euclidean_distance(face_encodings, face_to_compare):\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
    "\n",
    "\n",
    "def convert_image_numpy_array(file, mode='RGB'):\n",
    "    im = Image.open(file)\n",
    "    if mode:\n",
    "        im = im.convert(mode)\n",
    "    return np.array(im)\n",
    "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n",
    "    return list(euclidean_distance(known_face_encodings, face_encoding_to_check) <= tolerance)\n",
    "\n",
    "class FaceRecognitionGUI:\n",
    "    def __init__(self, persons_folder, output_file):\n",
    "        self.persons_folder = persons_folder\n",
    "        self.output_file = output_file\n",
    "        self.student_info = pd.DataFrame(columns=['Name', 'Time', 'Image'])\n",
    "        self.images = []\n",
    "        self.classNames = []\n",
    "        self.encodeListKnown = []\n",
    "\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title(\"Face Recognition\")\n",
    "\n",
    "        # Create a frame for the camera feed\n",
    "        self.camera_frame = tk.Frame(self.window)\n",
    "        self.camera_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Create a frame for the student info\n",
    "        self.info_frame = tk.Frame(self.window)\n",
    "        self.info_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Create a scrollable text area for student info\n",
    "        self.scrollbar = tk.Scrollbar(self.info_frame)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.text_area = tk.Text(self.info_frame, yscrollcommand=self.scrollbar.set)\n",
    "        self.text_area.pack()\n",
    "\n",
    "        self.scrollbar.config(command=self.text_area.yview)\n",
    "\n",
    "        # Start Recognition button\n",
    "        self.start_button = tk.Button(self.window, text=\"Start Recognition\", command=self.start_recognition)\n",
    "        self.start_button.pack(pady=10)\n",
    "\n",
    "        # Save to Excel button\n",
    "        self.save_button = tk.Button(self.window, text=\"Save to Excel\", command=self.save_to_excel)\n",
    "        self.save_button.pack(pady=10)\n",
    "\n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
    "\n",
    "        self.camera_thread = None\n",
    "        self.stop_camera = False\n",
    "\n",
    "    def on_close(self):\n",
    "        if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):\n",
    "            self.stop_camera = True\n",
    "            self.window.destroy()\n",
    "\n",
    "    def load_encodings_from_pickle(self):\n",
    "        # Load encodeListKnown and classNames from the pickle file\n",
    "        with open('encodings.pickle', 'rb') as f:\n",
    "            self.encodeListKnown = pickle.load(f)\n",
    "            self.classNames = pickle.load(f)\n",
    "\n",
    "    def recognize_faces(self):\n",
    "        self.load_encodings_from_pickle()\n",
    "        model = YOLO(\"yolov8_face.pt\")\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        while True:\n",
    "            if self.stop_camera:\n",
    "                break\n",
    "\n",
    "            _, img = cap.read()\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "            imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            detect_params = model.predict(source=[img], conf=0.45, save=False)\n",
    "\n",
    "            DP = detect_params[0].numpy()\n",
    "\n",
    "            if len(DP) != 0:\n",
    "                for i in range(len(detect_params[0])):\n",
    "                    boxes = detect_params[0].boxes\n",
    "                    box = boxes[i]\n",
    "                    bb = box.xyxy.numpy()[0]\n",
    "\n",
    "                    # Display class name and confidence\n",
    "                    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "                    # Clip the shape using the bounding box coordinates\n",
    "                    clipped_shape = img[int(bb[1]):int(bb[3]), int(bb[0]):int(bb[2])]\n",
    "\n",
    "                    # Compute face encoding for the clipped shape\n",
    "                    face_encodings = face_recognition.face_encodings(clipped_shape)\n",
    "\n",
    "                    if len(face_encodings) > 0:\n",
    "                        face_encoding = face_encodings[0]  # Assuming there's only one face in each frame\n",
    "                        for encodeFace, faceLoc in zip(face_encodings, clipped_shape):\n",
    "                            matches = compare_faces(self.encodeListKnown, encodeFace,tolerance=0.55)\n",
    "                            \n",
    "\n",
    "                        # Compare face encoding with data encodings\n",
    "                        face_distances = euclidean_distance(self.encodeListKnown, face_encoding)\n",
    "                        most_similar_index = np.argmin(face_distances)\n",
    "                        most_similar_image_name = self.classNames[most_similar_index]\n",
    "                        if np.any(matches):\n",
    "                            new_name = most_similar_image_name.replace('.jpg', '')\n",
    "\n",
    "                            # Display the name of the most similar image above the bounding box\n",
    "                            cv2.putText(img,new_name,(int(bb[0]), int(bb[1]) - 30),font,1,(255, 255, 255),1)\n",
    "\n",
    "                            # Draw rectangle around the face\n",
    "                            cv2.rectangle(img, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (0, 255, 0), 2)\n",
    "\n",
    "                            # Capture an image of the recognized student\n",
    "                            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                            image_filename = f\"recognized_{most_similar_image_name}_{timestamp}.jpg\"\n",
    "                            image_path = os.path.join(self.persons_folder, image_filename)\n",
    "                            # cv2.imwrite(image_path, clipped_shape)\n",
    "\n",
    "                            # Add student info to DataFrame\n",
    "                            self.add_student_info(new_name,\n",
    "                                                  datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                                  image_filename)\n",
    "                        else:\n",
    "                            # Draw rectangle around the clipped shape\n",
    "                            cv2.putText(img, \"Uknown\", (int(bb[0]), int(bb[1]) - 30), font, 1, (255, 0, 0), 1)\n",
    "                            cv2.rectangle(img, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (255, 0, 0), 2)\n",
    "\n",
    "            # Convert the image to PIL format and resize it\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((400, 300), Image.LANCZOS)\n",
    "            img = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "            # Display the image in a label\n",
    "            self.camera_label.config(image=img)\n",
    "            self.camera_label.image = img\n",
    "\n",
    "            # Update the student info in the text area\n",
    "            self.update_student_info()\n",
    "\n",
    "    def add_student_info(self, name, time, image_filename):\n",
    "        if name not in self.student_info['Name'].values:\n",
    "            new_row = {'Name': name, 'Time': time, 'Image': image_filename}\n",
    "            self.student_info = pd.concat([self.student_info, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "            self.update_student_info()\n",
    "\n",
    "    def update_student_info(self):\n",
    "        self.text_area.delete(1.0, tk.END)\n",
    "        for _, row in self.student_info.iterrows():\n",
    "            name = row['Name']\n",
    "            time = row['Time']\n",
    "            info_text = f'Name: {name}\\tTime: {time}\\n'\n",
    "            self.text_area.insert(tk.END, info_text)\n",
    "\n",
    "    def start_recognition(self):\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.load_encodings_from_pickle()\n",
    "        self.stop_camera = False\n",
    "        self.camera_thread = threading.Thread(target=self.recognize_faces)\n",
    "        self.camera_thread.start()\n",
    "\n",
    "    def save_to_excel(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\")\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        self.student_info.to_excel(file_path, index=False)\n",
    "        messagebox.showinfo(\"Success\", \"Student information saved to Excel file!\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        # Create a label for the camera feed\n",
    "        self.camera_label = tk.Label(self.camera_frame)\n",
    "        self.camera_label.pack()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    persons_folder = 'persons'\n",
    "    output_file = 'student_info.xlsx'\n",
    "\n",
    "    face_recognition_gui = FaceRecognitionGUI(persons_folder, output_file)\n",
    "    face_recognition_gui.run()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7091ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 144.2ms\n",
      "Speed: 3.8ms preprocess, 144.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 149.1ms\n",
      "Speed: 3.0ms preprocess, 149.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 151.4ms\n",
      "Speed: 3.0ms preprocess, 151.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name                 Time  \\\n",
      "0  Mohammed Alhydry  2023-07-30 12:25:40   \n",
      "\n",
      "                                               Image  \n",
      "0  persons\\recognized_Mohammed Alhydry_20230730_1...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 148.9ms\n",
      "Speed: 1.9ms preprocess, 148.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 140.8ms\n",
      "Speed: 1.8ms preprocess, 140.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 131.1ms\n",
      "Speed: 2.0ms preprocess, 131.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 140.8ms\n",
      "Speed: 2.2ms preprocess, 140.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name                 Time  \\\n",
      "0  Mohammed Alhydry  2023-07-30 12:25:40   \n",
      "1            Hassan  2023-07-30 12:25:42   \n",
      "\n",
      "                                               Image  \n",
      "0  persons\\recognized_Mohammed Alhydry_20230730_1...  \n",
      "1      persons\\recognized_Hassan_20230730_122542.jpg  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face, 144.9ms\n",
      "Speed: 3.1ms preprocess, 144.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 152.1ms\n",
      "Speed: 2.0ms preprocess, 152.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 135.3ms\n",
      "Speed: 3.0ms preprocess, 135.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 137.3ms\n",
      "Speed: 2.0ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 148.7ms\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 143.5ms\n",
      "Speed: 1.0ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 145.1ms\n",
      "Speed: 2.9ms preprocess, 145.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 139.7ms\n",
      "Speed: 2.0ms preprocess, 139.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 148.8ms\n",
      "Speed: 2.5ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 153.6ms\n",
      "Speed: 2.6ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 144.8ms\n",
      "Speed: 3.0ms preprocess, 144.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 144.5ms\n",
      "Speed: 2.0ms preprocess, 144.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 156.7ms\n",
      "Speed: 3.5ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 169.4ms\n",
      "Speed: 2.0ms preprocess, 169.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 166.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name                 Time  \\\n",
      "0  Mohammed Alhydry  2023-07-30 12:25:40   \n",
      "1            Hassan  2023-07-30 12:25:42   \n",
      "2         Abdulaziz  2023-07-30 12:25:48   \n",
      "\n",
      "                                               Image  \n",
      "0  persons\\recognized_Mohammed Alhydry_20230730_1...  \n",
      "1      persons\\recognized_Hassan_20230730_122542.jpg  \n",
      "2   persons\\recognized_Abdulaziz_20230730_122548.jpg  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 166.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 143.5ms\n",
      "Speed: 2.0ms preprocess, 143.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 145.4ms\n",
      "Speed: 3.2ms preprocess, 145.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 134.0ms\n",
      "Speed: 3.0ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 144.2ms\n",
      "Speed: 2.0ms preprocess, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 faces, 138.3ms\n",
      "Speed: 2.4ms preprocess, 138.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 152.6ms\n",
      "Speed: 2.5ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.7ms\n",
      "Speed: 1.0ms preprocess, 150.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.3ms\n",
      "Speed: 2.0ms preprocess, 157.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.3ms\n",
      "Speed: 2.4ms preprocess, 163.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.7ms\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 149.3ms\n",
      "Speed: 2.0ms preprocess, 149.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 148.0ms\n",
      "Speed: 4.0ms preprocess, 148.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.2ms\n",
      "Speed: 4.2ms preprocess, 154.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.9ms\n",
      "Speed: 2.0ms preprocess, 156.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.3ms\n",
      "Speed: 1.7ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 140.2ms\n",
      "Speed: 2.0ms preprocess, 140.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 152.8ms\n",
      "Speed: 2.5ms preprocess, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.0ms\n",
      "Speed: 4.0ms preprocess, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.7ms\n",
      "Speed: 2.9ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 136.5ms\n",
      "Speed: 2.0ms preprocess, 136.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 153.2ms\n",
      "Speed: 2.0ms preprocess, 153.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.6ms\n",
      "Speed: 3.0ms preprocess, 150.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.7ms\n",
      "Speed: 2.6ms preprocess, 226.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.0ms\n",
      "Speed: 2.9ms preprocess, 209.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 190.4ms\n",
      "Speed: 2.8ms preprocess, 190.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.6ms\n",
      "Speed: 4.8ms preprocess, 201.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 158.3ms\n",
      "Speed: 2.0ms preprocess, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.9ms\n",
      "Speed: 2.1ms preprocess, 165.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.2ms\n",
      "Speed: 2.1ms preprocess, 160.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 149.3ms\n",
      "Speed: 3.6ms preprocess, 149.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 149.9ms\n",
      "Speed: 2.2ms preprocess, 149.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.6ms\n",
      "Speed: 5.9ms preprocess, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.9ms\n",
      "Speed: 2.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.9ms\n",
      "Speed: 2.5ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 144.3ms\n",
      "Speed: 2.0ms preprocess, 144.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.1ms\n",
      "Speed: 2.7ms preprocess, 156.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.5ms\n",
      "Speed: 2.0ms preprocess, 170.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 151.3ms\n",
      "Speed: 3.0ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.3ms\n",
      "Speed: 2.0ms preprocess, 142.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 159.3ms\n",
      "Speed: 2.0ms preprocess, 159.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 144.2ms\n",
      "Speed: 2.0ms preprocess, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.8ms\n",
      "Speed: 2.0ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.2ms\n",
      "Speed: 2.0ms preprocess, 163.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.3ms\n",
      "Speed: 2.7ms preprocess, 154.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 172.0ms\n",
      "Speed: 2.0ms preprocess, 172.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.7ms\n",
      "Speed: 2.6ms preprocess, 182.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.2ms\n",
      "Speed: 2.0ms preprocess, 165.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 153.7ms\n",
      "Speed: 3.4ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.4ms\n",
      "Speed: 3.3ms preprocess, 154.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 155.0ms\n",
      "Speed: 2.5ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 158.6ms\n",
      "Speed: 1.8ms preprocess, 158.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 153.2ms\n",
      "Speed: 3.3ms preprocess, 153.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.1ms\n",
      "Speed: 2.0ms preprocess, 157.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.9ms\n",
      "Speed: 2.4ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.2ms\n",
      "Speed: 2.0ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.4ms\n",
      "Speed: 2.2ms preprocess, 157.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 149.7ms\n",
      "Speed: 2.0ms preprocess, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.4ms\n",
      "Speed: 3.0ms preprocess, 157.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 144.9ms\n",
      "Speed: 2.0ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 142.0ms\n",
      "Speed: 2.5ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.3ms\n",
      "Speed: 2.0ms preprocess, 191.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.4ms\n",
      "Speed: 2.0ms preprocess, 174.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 2.4ms preprocess, 176.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.0ms\n",
      "Speed: 2.5ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.3ms\n",
      "Speed: 2.2ms preprocess, 182.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.2ms\n",
      "Speed: 2.9ms preprocess, 237.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.7ms\n",
      "Speed: 5.9ms preprocess, 224.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.6ms\n",
      "Speed: 2.0ms preprocess, 180.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 177.1ms\n",
      "Speed: 2.8ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 211.5ms\n",
      "Speed: 1.9ms preprocess, 211.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 175.9ms\n",
      "Speed: 3.7ms preprocess, 175.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.3ms\n",
      "Speed: 4.6ms preprocess, 201.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.0ms\n",
      "Speed: 3.4ms preprocess, 189.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.7ms\n",
      "Speed: 3.2ms preprocess, 170.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.9ms\n",
      "Speed: 3.4ms preprocess, 174.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 157.2ms\n",
      "Speed: 2.5ms preprocess, 157.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.7ms\n",
      "Speed: 2.3ms preprocess, 163.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 167.8ms\n",
      "Speed: 2.5ms preprocess, 167.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.9ms\n",
      "Speed: 2.4ms preprocess, 165.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.7ms\n",
      "Speed: 3.0ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 146.7ms\n",
      "Speed: 2.5ms preprocess, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 150.2ms\n",
      "Speed: 1.0ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.2ms\n",
      "Speed: 3.0ms preprocess, 154.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 145.6ms\n",
      "Speed: 2.1ms preprocess, 145.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 152.4ms\n",
      "Speed: 2.0ms preprocess, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 138.4ms\n",
      "Speed: 3.4ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 154.8ms\n",
      "Speed: 1.5ms preprocess, 154.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 145.2ms\n",
      "Speed: 2.0ms preprocess, 145.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 147.4ms\n",
      "Speed: 2.0ms preprocess, 147.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 141.2ms\n",
      "Speed: 3.0ms preprocess, 141.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 134.9ms\n",
      "Speed: 1.0ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 146.4ms\n",
      "Speed: 2.0ms preprocess, 146.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.4ms\n",
      "Speed: 2.0ms preprocess, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 140.8ms\n",
      "Speed: 2.6ms preprocess, 140.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 147.8ms\n",
      "Speed: 2.9ms preprocess, 147.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 141.2ms\n",
      "Speed: 2.5ms preprocess, 141.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 147.7ms\n",
      "Speed: 2.0ms preprocess, 147.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 242.4ms\n",
      "Speed: 5.9ms preprocess, 242.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face, 152.4ms\n",
      "Speed: 3.5ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 162.2ms\n",
      "Speed: 2.5ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 155.8ms\n",
      "Speed: 2.0ms preprocess, 155.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 162.7ms\n",
      "Speed: 2.0ms preprocess, 162.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 431.6ms\n",
      "Speed: 2.0ms preprocess, 431.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.9ms\n",
      "Speed: 5.6ms preprocess, 226.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 215.6ms\n",
      "Speed: 6.5ms preprocess, 215.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.4ms\n",
      "Speed: 2.8ms preprocess, 183.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.7ms\n",
      "Speed: 2.6ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 163.2ms\n",
      "Speed: 2.1ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 152.0ms\n",
      "Speed: 1.9ms preprocess, 152.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 148.5ms\n",
      "Speed: 2.0ms preprocess, 148.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.8ms\n",
      "Speed: 2.0ms preprocess, 156.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.1ms\n",
      "Speed: 2.1ms preprocess, 183.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 158.1ms\n",
      "Speed: 3.8ms preprocess, 158.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.6ms\n",
      "Speed: 2.1ms preprocess, 160.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 161.5ms\n",
      "Speed: 2.5ms preprocess, 161.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 161.4ms\n",
      "Speed: 2.0ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 153.7ms\n",
      "Speed: 2.6ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 177.0ms\n",
      "Speed: 11.1ms preprocess, 177.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 164.7ms\n",
      "Speed: 2.0ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 143.5ms\n",
      "Speed: 3.0ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 155.3ms\n",
      "Speed: 1.0ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.4ms\n",
      "Speed: 3.0ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 158.0ms\n",
      "Speed: 3.5ms preprocess, 158.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 152.9ms\n",
      "Speed: 5.2ms preprocess, 152.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 458.7ms\n",
      "Speed: 3.3ms preprocess, 458.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Exception in thread Thread-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\shahad mohammed\\AppData\\Local\\Temp\\ipykernel_15200\\3843648801.py\", line 182, in recognize_faces\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\site-packages\\PIL\\ImageTk.py\", line 127, in __init__\n",
      "    self.__photo = tkinter.PhotoImage(**kw)\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\tkinter\\__init__.py\", line 4064, in __init__\n",
      "    Image.__init__(self, 'photo', name, cnf, master, **kw)\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\tkinter\\__init__.py\", line 3997, in __init__\n",
      "    master = _get_default_root('create image')\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\tkinter\\__init__.py\", line 297, in _get_default_root\n",
      "    raise RuntimeError(f\"Too early to {what}: no default root window\")\n",
      "RuntimeError: Too early to create image: no default root window\n",
      "Exception ignored in: <function PhotoImage.__del__ at 0x0000026643AC5820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anaconda\\envs\\face_recognation\\lib\\site-packages\\PIL\\ImageTk.py\", line 133, in __del__\n",
      "    name = self.__photo.name\n",
      "AttributeError: 'PhotoImage' object has no attribute '_PhotoImage__photo'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "import pickle\n",
    "from openpyxl.drawing.image import Image as XlImg\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance(face_encodings, face_to_compare):\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
    "\n",
    "\n",
    "def convert_image_numpy_array(file, mode='RGB'):\n",
    "    im = Image.open(file)\n",
    "    if mode:\n",
    "        im = im.convert(mode)\n",
    "    return np.array(im)\n",
    "\n",
    "\n",
    "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n",
    "    return list(euclidean_distance(known_face_encodings, face_encoding_to_check) <= tolerance)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class FaceRecognitionGUI:\n",
    "    \n",
    "    def __init__(self, persons_folder, output_file):\n",
    "        \n",
    "        self.persons_folder = persons_folder\n",
    "        self.output_file = output_file\n",
    "        self.student_info = pd.DataFrame(columns=['Name', 'Time', 'Image'])\n",
    "        self.images = []\n",
    "        self.classNames = []\n",
    "        self.encodeListKnown = []\n",
    "\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title(\"Face Recognition\")\n",
    "\n",
    "        # Create a frame for the camera feed\n",
    "        self.camera_frame = tk.Frame(self.window)\n",
    "        self.camera_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Create a frame for the student info\n",
    "        self.info_frame = tk.Frame(self.window)\n",
    "        self.info_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Create a scrollable text area for student info\n",
    "        self.scrollbar = tk.Scrollbar(self.info_frame)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.text_area = tk.Text(self.info_frame, yscrollcommand=self.scrollbar.set)\n",
    "        self.text_area.pack()\n",
    "\n",
    "        self.scrollbar.config(command=self.text_area.yview)\n",
    "\n",
    "        # Start Recognition button\n",
    "        self.start_button = tk.Button(self.window, text=\"Start Recognition\", command=self.start_recognition)\n",
    "        self.start_button.pack(pady=10)\n",
    "\n",
    "        # Save to Excel button\n",
    "        self.save_button = tk.Button(self.window, text=\"Save to Excel\", command=self.save_to_excel)\n",
    "        self.save_button.pack(pady=10)\n",
    "\n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
    "\n",
    "        self.camera_thread = None\n",
    "        self.stop_camera = False\n",
    "\n",
    "    def on_close(self):\n",
    "        if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):\n",
    "            self.stop_camera = True\n",
    "            self.window.destroy()\n",
    "\n",
    "    def load_encodings_from_pickle(self):\n",
    "        # Load encodeListKnown and classNames from the pickle file\n",
    "        with open('encodings.pickle', 'rb') as f:\n",
    "            self.encodeListKnown = pickle.load(f)\n",
    "            self.classNames = pickle.load(f)\n",
    "\n",
    " \n",
    "\n",
    "    def recognize_faces(self):\n",
    "        self.load_encodings_from_pickle()\n",
    "        model = YOLO(\"yolov8_face.pt\")\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        while True:\n",
    "            if self.stop_camera:\n",
    "                break\n",
    "\n",
    "            _, img = cap.read()\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "            imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            detect_params = model.predict(source=[img], conf=0.45, save=False)\n",
    "\n",
    "            DP = detect_params[0].numpy()\n",
    "\n",
    "            if len(DP) != 0:\n",
    "                \n",
    "                for i in range(len(detect_params[0])):\n",
    "                    boxes = detect_params[0].boxes\n",
    "                    box = boxes[i]\n",
    "                    bb = box.xyxy.numpy()[0]\n",
    "\n",
    "                    # Display class name and confidence\n",
    "                    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "                    # Clip the shape using the bounding box coordinates\n",
    "                    clipped_shape = img[int(bb[1]):int(bb[3]), int(bb[0]):int(bb[2])]\n",
    "           \n",
    "                    # Convert array to numpy array \n",
    "                    # It was the strangest error I have faced\n",
    "                    clipped_shape = np.array(clipped_shape)\n",
    "                 \n",
    "                    face_encodings = face_recognition.face_encodings(clipped_shape)\n",
    "                \n",
    "\n",
    "                    if len(face_encodings) > 0:\n",
    "                        face_encoding = face_encodings[0]  # Assuming there's only one face in each frame\n",
    "                        for encodeFace, faceLoc in zip(face_encodings, clipped_shape):\n",
    "                            matches = compare_faces(self.encodeListKnown, encodeFace,tolerance=0.55)\n",
    "                            \n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    # Compare face encoding with data encodings\n",
    "                    face_distances = euclidean_distance(self.encodeListKnown, face_encoding)\n",
    "                    most_similar_index = np.argmin(face_distances)\n",
    "                    most_similar_image_name = self.classNames[most_similar_index]\n",
    "                        \n",
    "                    if np.any(matches):\n",
    "                        new_name = most_similar_image_name.replace('.jpg', '')\n",
    "\n",
    "                        # Display the name of the most similar image above the bounding box\n",
    "                        cv2.putText(img,new_name,(int(bb[0]), int(bb[1]) - 30),font,1,(255, 255, 255),1)\n",
    "\n",
    "                        # Draw rectangle around the face\n",
    "                        cv2.rectangle(img, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (0, 255, 0), 2)\n",
    "\n",
    "                        # Capture an image of the recognized student\n",
    "                        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                        image_filename = f\"recognized_{most_similar_image_name}_{timestamp}.jpg\"\n",
    "                        image_path = os.path.join(self.persons_folder, image_filename)\n",
    "                        cv2.imwrite(image_path, clipped_shape)\n",
    "                    \n",
    "\n",
    "                        # Add student info to DataFrame\n",
    "                        self.add_student_info(new_name,\n",
    "                                              datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                              image_path)\n",
    "                    else:\n",
    "                        # Draw rectangle around the clipped shape\n",
    "                        cv2.putText(img, \"Uknown\", (int(bb[0]), int(bb[1]) - 30), font, 1, (255, 0, 0), 1)\n",
    "                        cv2.rectangle(img, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (255, 0, 0), 2)\n",
    "\n",
    "                            \n",
    "                            \n",
    "            # Convert the image to PIL format and resize it\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((400, 300), Image.LANCZOS)\n",
    "            img = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "            # Display the image in a label\n",
    "            self.camera_label.config(image=img)\n",
    "            self.camera_label.image = img\n",
    "\n",
    "            # Update the student info in the text area\n",
    "            self.update_student_info()\n",
    "\n",
    "    def add_student_info(self, name, time, image_filename):\n",
    "        if name not in self.student_info['Name'].values:\n",
    "            new_row = {'Name': name, 'Time': time, 'Image': image_filename}\n",
    "            self.student_info = pd.concat([self.student_info, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "            self.update_student_info()\n",
    "            print(self.student_info)\n",
    "\n",
    "    def update_student_info(self):\n",
    "        self.text_area.delete(1.0, tk.END)\n",
    "        for _, row in self.student_info.iterrows():\n",
    "            name = row['Name']\n",
    "            time = row['Time']\n",
    "            info_text = f'Name: {name}\\tTime: {time}\\n'\n",
    "            self.text_area.insert(tk.END, info_text)\n",
    "\n",
    "    def start_recognition(self):\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.load_encodings_from_pickle()\n",
    "        self.stop_camera = False\n",
    "        self.camera_thread = threading.Thread(target=self.recognize_faces)\n",
    "        self.camera_thread.start()\n",
    "\n",
    "    def save_to_excel(self):\n",
    "        \n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\")\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        \n",
    "        ws.column_dimensions['A'].width = 20\n",
    "        ws.column_dimensions['B'].width = 20\n",
    "        \n",
    "\n",
    "        for index, row in self.student_info.iterrows():\n",
    "            \n",
    "            index = index + 1\n",
    "            ws.cell(row=index, column=1).value = row['Name']\n",
    "            ws.cell(row=index, column=2).value = row['Time']\n",
    "\n",
    "            img = XlImg(row['Image'])\n",
    "            img.width = 60\n",
    "            img.height = 80\n",
    "            img_ref = ws.column_dimensions['C']\n",
    "            img_ref.width = img.width // 6\n",
    "            ws.row_dimensions[index].height = img.height\n",
    "            ws.add_image(img, f'C{index}')\n",
    "\n",
    "\n",
    "        wb.save(file_path)\n",
    "        messagebox.showinfo(\"Success\", \"Student information saved to Excel file!\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        # Create a label for the camera feed\n",
    "        self.camera_label = tk.Label(self.camera_frame)\n",
    "        self.camera_label.pack()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    persons_folder = 'persons'\n",
    "    output_file = 'Attendence.xlsx'\n",
    "    \n",
    "    print('start')\n",
    "\n",
    "    face_recognition_gui = FaceRecognitionGUI(persons_folder, output_file)\n",
    "    \n",
    "    print('run')\n",
    "    face_recognition_gui.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
